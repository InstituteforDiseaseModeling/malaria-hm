{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malaria addInputEIR calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A history matching approach to calibrating an empirical model of malaria infection and immunity\n",
    "\n",
    "### In this version, we will be utilizing the full immune parameter space, sampling also which immune forces should be included in the calculation of the immune modifier (ie configurable params starting with \"Immune_Modifier_Include*\"\n",
    "\n",
    "### For iter0 we will cut down parameter space by using the distribution of malaria prevalence by season, age and density bins from a moderate high transmission setting in Sugungum, Garki, Nigeria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\envs\\history_matching\\lib\\site-packages\\skcuda\\cublas.py:284: UserWarning: creating CUBLAS context to get version number\n",
      "  warnings.warn('creating CUBLAS context to get version number')\n"
     ]
    }
   ],
   "source": [
    "from IPython.extensions import autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, glob, re, sys, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "from calibtool.analyzers.Helpers import \\\n",
    "    convert_to_counts, age_from_birth_cohort, season_from_time, aggregate_on_index\n",
    "\n",
    "from wand.image import Image as WImage\n",
    "from history_matching import HistoryMatching, HistoryMatchingCut, quick_read, Basis\n",
    "\n",
    "import pycuda\n",
    "from IPython.display import IFrame, display\n",
    "\n",
    "from pyDOE import lhs\n",
    "from history_matching import HistoryMatching, HistoryMatchingCut, quick_read, Basis\n",
    "sns.set(font_scale=2)\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_glob(pth):\n",
    "    return re.sub('([\\[\\]])','[\\\\1]', pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure parameters and data for history matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'Sugungum'\n",
    "season_cut = 'W2'\n",
    "age_bin_cut = 8\n",
    "density_bin_cut = 500\n",
    "\n",
    "cut_name = f'{density_bin_cut}_{age_bin_cut}_{season_cut}_{site}'\n",
    "\n",
    "#iteration = int(re.search(r'iter(\\d+)', os.getcwd())) # Index of the current iteration\n",
    "iteration = 2\n",
    "\n",
    "#list of exp_ids/folders that correspond to exp_ids from which our emulation will draw\n",
    "exp_ids = ['7d95a4cd-dd60-ea11-a2c5-c4346bcb1550'] # TODO: only uses first for now, should loop\n",
    "basedir = 'C:\\git\\Malaria-Uganda-PRISM'\n",
    "datafile = os.path.join('..','reference data', 'Garki_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The implausibility threshold determines how willing we are to retain regions\n",
    "# of parameter space that are inconsistent with the underlying data. A higher\n",
    "# threshold is more risk averse in that potentially good regions are less likely\n",
    "# to be rejected, however it will take more iterations/simulations to achieve results.\n",
    "implausibility_threshold = 3\n",
    "training_fraction = 0.75 # Fraction of simulations to use as training\n",
    "discrepancy_std = 0.0 # Accounts for uncertainty w.r.t model structure\n",
    "n_samples_to_generate_for_next_iter = 1000 # Number of simulations to conduct on this iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Params from ..\\Params_c686920dee8501a26fe576ed61915351.hd5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>MapTo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Biological_Age_Immune_Coefficient_PPP</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Biological_Age_Immune_Coefficient_PPP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biological_Age_Immune_Coefficient_TM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Biological_Age_Immune_Coefficient_TM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative_Exposure_Immune_Coefficient_PPP</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Cumulative_Exposure_Immune_Coefficient_PPP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative_Exposure_Immune_Coefficient_TM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumulative_Exposure_Immune_Coefficient_TM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scale_Factor_Age_a</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Scale_Factor_Age_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parasite_Density_Wave_Sigma</th>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>Parasite_Density_Wave_Sigma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Immune_Modifier_Include_Age</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Immune_Modifier_Include_Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Immune_Modifier_Include_Cumulative_Exposure</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Immune_Modifier_Include_Cumulative_Exposure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Min  Max  \\\n",
       "Name                                                    \n",
       "Biological_Age_Immune_Coefficient_PPP        0.0   10   \n",
       "Biological_Age_Immune_Coefficient_TM         0.0    1   \n",
       "Cumulative_Exposure_Immune_Coefficient_PPP   0.0   10   \n",
       "Cumulative_Exposure_Immune_Coefficient_TM    0.0    1   \n",
       "Scale_Factor_Age_a                           3.0    5   \n",
       "Parasite_Density_Wave_Sigma                  0.6    6   \n",
       "Immune_Modifier_Include_Age                  0.0    1   \n",
       "Immune_Modifier_Include_Cumulative_Exposure  0.0    1   \n",
       "\n",
       "                                                                                   MapTo  \n",
       "Name                                                                                      \n",
       "Biological_Age_Immune_Coefficient_PPP              Biological_Age_Immune_Coefficient_PPP  \n",
       "Biological_Age_Immune_Coefficient_TM                Biological_Age_Immune_Coefficient_TM  \n",
       "Cumulative_Exposure_Immune_Coefficient_PPP    Cumulative_Exposure_Immune_Coefficient_PPP  \n",
       "Cumulative_Exposure_Immune_Coefficient_TM      Cumulative_Exposure_Immune_Coefficient_TM  \n",
       "Scale_Factor_Age_a                                                    Scale_Factor_Age_a  \n",
       "Parasite_Density_Wave_Sigma                                  Parasite_Density_Wave_Sigma  \n",
       "Immune_Modifier_Include_Age                                  Immune_Modifier_Include_Age  \n",
       "Immune_Modifier_Include_Cumulative_Exposure  Immune_Modifier_Include_Cumulative_Exposure  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we define the parameter names and ranges\n",
    "params_file = os.path.join('..','Params.xlsx')\n",
    "param_info = quick_read(params_file, 'Params').set_index('Name')\n",
    "param_names = param_info.index.tolist()\n",
    "\n",
    "params = param_info.index.values\n",
    "n_params = param_info.shape[0] # We'll use this one place later\n",
    "display(param_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Sim Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "Experiment: 7d95a4cd-dd60-ea11-a2c5-c4346bcb1550\n",
      "7d95a4cd-dd60-ea11-a2c5-c4346bcb1550\\full_analyzer_results.csv\n",
      "     Unnamed: 0  sample                                sim_id season  age_bin  \\\n",
      "51            0       0  ddcdb4d3-dd60-ea11-a2c5-c4346bcb1550     W2        8   \n",
      "114           0      15  eccdb4d3-dd60-ea11-a2c5-c4346bcb1550     W2        8   \n",
      "177           0      39  12ceb4d3-dd60-ea11-a2c5-c4346bcb1550     W2        8   \n",
      "240           0       6  e3cdb4d3-dd60-ea11-a2c5-c4346bcb1550     W2        8   \n",
      "303           0      41  fbcdb4d3-dd60-ea11-a2c5-c4346bcb1550     W2        8   \n",
      "\n",
      "     density_bin     value  \n",
      "51           500  0.100363  \n",
      "114          500  0.057128  \n",
      "177          500  0.139272  \n",
      "240          500  0.133271  \n",
      "303          500  0.060169  \n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Sim_Result</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample_Id</th>\n",
       "      <th>Sim_Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7d95a4cd-dd60-ea11-a2c5-c4346bcb1550.000000</th>\n",
       "      <th>ddcdb4d3-dd60-ea11-a2c5-c4346bcb1550</th>\n",
       "      <td>0.100363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d95a4cd-dd60-ea11-a2c5-c4346bcb1550.000001</th>\n",
       "      <th>decdb4d3-dd60-ea11-a2c5-c4346bcb1550</th>\n",
       "      <td>0.080972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d95a4cd-dd60-ea11-a2c5-c4346bcb1550.000002</th>\n",
       "      <th>dfcdb4d3-dd60-ea11-a2c5-c4346bcb1550</th>\n",
       "      <td>0.062837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d95a4cd-dd60-ea11-a2c5-c4346bcb1550.000003</th>\n",
       "      <th>e0cdb4d3-dd60-ea11-a2c5-c4346bcb1550</th>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d95a4cd-dd60-ea11-a2c5-c4346bcb1550.000004</th>\n",
       "      <th>e1cdb4d3-dd60-ea11-a2c5-c4346bcb1550</th>\n",
       "      <td>0.074647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  Sim_Result\n",
       "Sample_Id                                   Sim_Id                                          \n",
       "7d95a4cd-dd60-ea11-a2c5-c4346bcb1550.000000 ddcdb4d3-dd60-ea11-a2c5-c4346bcb1550    0.100363\n",
       "7d95a4cd-dd60-ea11-a2c5-c4346bcb1550.000001 decdb4d3-dd60-ea11-a2c5-c4346bcb1550    0.080972\n",
       "7d95a4cd-dd60-ea11-a2c5-c4346bcb1550.000002 dfcdb4d3-dd60-ea11-a2c5-c4346bcb1550    0.062837\n",
       "7d95a4cd-dd60-ea11-a2c5-c4346bcb1550.000003 e0cdb4d3-dd60-ea11-a2c5-c4346bcb1550    0.049505\n",
       "7d95a4cd-dd60-ea11-a2c5-c4346bcb1550.000004 e1cdb4d3-dd60-ea11-a2c5-c4346bcb1550    0.074647"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_samples = []\n",
    "all_results = []\n",
    "for exp_id in exp_ids:\n",
    "    \n",
    "    print('-'*80, '\\nExperiment:', exp_id)\n",
    "    sim_results_fn = os.path.join(exp_id, 'full_analyzer_results.csv')\n",
    "    print(sim_results_fn)\n",
    "    sr = pd.read_csv(sim_results_fn, skipinitialspace=True)\n",
    "    \n",
    "    sr = sr[(sr.season == season_cut)&(sr.age_bin ==age_bin_cut)&(sr.density_bin==density_bin_cut)]\n",
    "    print(sr.head())\n",
    "    sr['Sample_Id'] = sr['sample'].apply(lambda x: '%s.%06d' % (exp_id, x))\n",
    "    sr.rename(columns = {'sim_id': 'Sim_Id','value':'Result'}, inplace=True)\n",
    "    all_results.append( sr )\n",
    "    #read in tags making a samples.xlsx file \n",
    "    s = pd.read_excel(os.path.join(exp_id, 'Samples.xlsx'))\n",
    "    # s.drop('Sim_Id', axis=1, inplace=True)\n",
    "    s['Sample_Id'] = s['Sample'].apply(lambda x: '%s.%06d' % (exp_id, x))\n",
    "    all_samples.append( s )\n",
    "\n",
    "#.rename(columns={'level_1': 'Year', 0: 'Cases'}) \\\n",
    "all_results = pd.concat(all_results) \\\n",
    "    .set_index(['Sample_Id', 'Sim_Id']) \\\n",
    "    [['Result']] \\\n",
    "    .sort_index()\n",
    "\n",
    "samples = pd.concat(all_samples).set_index('Sample_Id').sort_index() # Bad because sample will be repeated across exp_id!\n",
    "                       \n",
    "samples.to_csv('Samples.csv')\n",
    "all_results.to_csv('Results.csv')\n",
    "results = all_results['Result']\n",
    "\n",
    "results = all_results \\\n",
    "    .groupby(['Sample_Id', 'Sim_Id']) \\\n",
    "    .mean()\n",
    "\n",
    "    \n",
    "results.rename(columns={'Result':'Sim_Result'}, inplace=True)\n",
    "print(type(results))\n",
    "display(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouped_df(df, pfprdict, index, column_keep, column_del):\n",
    "    \"\"\"\n",
    "    Recut dataframe to recategorize data into desired age and parasitemia bins\n",
    "\n",
    "    Args:\n",
    "        df: Dataframe to be rebinned\n",
    "        pfprdict: Dictionary mapping postive counts per slide view (http://garkiproject.nd.edu/demographic-parasitological-surveys.html)\n",
    "                to density of parasites/gametocytes per uL\n",
    "        index: Multi index into which 'df' is rebinned\n",
    "        column_keep: Column (e.g. parasitemia) to keep\n",
    "        column_del: Column (e.g. gametocytemia) to delete\n",
    "    \"\"\"\n",
    "    dftemp = df.copy()\n",
    "    del dftemp[column_del]\n",
    "\n",
    "    dftemp['PfPR Bin'] = df[column_keep]\n",
    "    dftemp = aggregate_on_index(dftemp, index)\n",
    "\n",
    "    dfGrouped = dftemp.groupby(['Season', 'Age Bin', 'PfPR Bin'])\n",
    "\n",
    "    dftemp = dfGrouped[column_keep].count()\n",
    "    dftemp = dftemp.unstack().fillna(0).stack()\n",
    "    dftemp = dftemp.rename(column_keep).reset_index()\n",
    "    dftemp['PfPR Bin'] = [pfprdict[p] for p in dftemp['PfPR Bin']]\n",
    "\n",
    "    dftemp = dftemp.set_index(['Season', 'Age Bin', 'PfPR Bin'])\n",
    "\n",
    "    return dftemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\envs\\history_matching\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  app.launch_new_instance()\n",
      "C:\\conda\\envs\\history_matching\\lib\\site-packages\\pandas\\core\\generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "ref_data_path = os.path.join('..','reference data','Garki_df.csv')\n",
    "df = pd.read_csv(ref_data_path)\n",
    "\n",
    "self = pd.DataFrame()\n",
    "self.metadata =  {\n",
    "        'density_bins': [0, 50, 200, 500, np.inf],  # (, 0] (0, 50] ... (50000, ]\n",
    "        'density_bin_edges':['0', '50', '200', '500'],\n",
    "        'age_bins': [0, 1, 4, 8, 18, 28, 43, np.inf],  # (, 5] (5, 15] (15, ],\n",
    "        'age_bin_labels':['<1', '1-4', '4-8', '8-18', '18-28', '28-43', '>43'],\n",
    "        'seasons': ['DC2', 'DH2', 'W2'],\n",
    "        'seasons_by_month': {\n",
    "            'Apr': 'DH2',\n",
    "            'June/Aug': 'W2',\n",
    "            'Dec/Jan': 'DC2'\n",
    "        },\n",
    "        'village': 'Sugungum'\n",
    "    }\n",
    "\n",
    "df = df.loc[df['Village']==self.metadata['village']]\n",
    "pfprBinsDensity = self.metadata['density_bins']\n",
    "uL_per_field = 0.5 / 200.0  # from Garki PDF - page 111 - 0.5 uL per 200 views\n",
    "pfprBins = 1 - np.exp(-np.asarray(pfprBinsDensity) * uL_per_field)\n",
    "seasons = self.metadata['seasons']\n",
    "pfprdict = dict(zip(pfprBins, pfprBinsDensity))\n",
    "\n",
    "bins = OrderedDict([\n",
    "    ('Season', self.metadata['seasons']),\n",
    "    ('Age Bin', self.metadata['age_bins']),\n",
    "    ('PfPR Bin', pfprBins)\n",
    "])\n",
    "bin_tuples = list(itertools.product(*bins.values()))\n",
    "index = pd.MultiIndex.from_tuples(bin_tuples, names=bins.keys())\n",
    "\n",
    "df = df.loc[df['Seasons'].isin(seasons)]\n",
    "df = df.rename(columns={'Seasons': 'Season', 'Age': 'Age Bin'})\n",
    "\n",
    "df2 = grouped_df(df, pfprdict, index, 'Parasitemia', 'Gametocytemia')\n",
    "df3 = grouped_df(df, pfprdict, index, 'Gametocytemia', 'Parasitemia')\n",
    "dfJoined = df2.join(df3).fillna(0)\n",
    "dfJoined = pd.concat([dfJoined['Gametocytemia'], dfJoined['Parasitemia']])\n",
    "dfJoined.name = 'Counts'\n",
    "dftemp = dfJoined.reset_index()\n",
    "dftemp['Channel'] = 'PfPR by Gametocytemia and Age Bin'\n",
    "dftemp.loc[len(dftemp) / 2:, 'Channel'] = 'PfPR by Parasitemia and Age Bin'\n",
    "dftemp = dftemp.rename(columns={'Seasons': 'Season', 'PfPR Bins': 'PfPR Bin', 'Age Bins': 'Age Bin'})\n",
    "dftemp = dftemp.set_index(['Channel', 'Season', 'Age Bin', 'PfPR Bin'])\n",
    "\n",
    "# how to set the cwd\n",
    "ref_data =dftemp\n",
    "ref_data['bin_pop'] = ref_data.groupby(by=['Channel', 'Season', 'Age Bin'])['Counts'].sum()\n",
    "ref_data['proportion'] = ref_data['Counts'] / ref_data['bin_pop']\n",
    "ref_data.reset_index(inplace=True)\n",
    "ref_data = ref_data[ref_data['Channel'] == 'PfPR by Parasitemia and Age Bin']\n",
    "\n",
    "new_ref_df = pd.DataFrame()\n",
    "for i, grouping in ref_data.groupby(by=['Channel', 'Season', 'Age Bin']):\n",
    "    group_subset = pd.DataFrame()\n",
    "    \n",
    "    low = grouping[grouping['PfPR Bin'] == 50]\n",
    "    low.proportion += grouping[grouping['PfPR Bin'] == 0]['proportion'].values[0]\n",
    "        \n",
    "    middle = grouping[grouping['PfPR Bin'] == 500]\n",
    "    middle.proportion += grouping[grouping['PfPR Bin'] == 200]['proportion'].values[0]\n",
    "    \n",
    "    high = grouping[grouping['PfPR Bin'] == np.inf]\n",
    "    new_ref_df = pd.concat([new_ref_df,low,middle,high])\n",
    "new_ref_df.drop('Counts',axis = 1, inplace=True)    \n",
    "new_ref_df = new_ref_df[(new_ref_df.Season == season_cut) & (new_ref_df['Age Bin'] == age_bin_cut) & (new_ref_df['PfPR Bin'] == density_bin_cut)]\n",
    "new_ref_df['binomial error'] = np.sqrt((new_ref_df['proportion']*(1-new_ref_df['proportion']))/new_ref_df['bin_pop'])\n",
    "print(new_ref_df)\n",
    "mean = new_ref_df.proportion\n",
    "error = new_ref_df['binomial error']\n",
    "\n",
    "\n",
    "desired_result = mean.values[0]\n",
    "desired_result_std = error.values[0]\n",
    "\n",
    "print('Before logit, desired result is %.3f [%.3f, %.3f]: ' % (desired_result, desired_result-2*desired_result_std, desired_result+2*desired_result_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = pd.merge(samples, results, on='Sample_Id') # Return to Sample_Id\n",
    "\n",
    "#sub in variables here, can be list of tuples\n",
    "xyvars = [('Parasite_Density_Wave_Sigma',\t'Biological_Age_Immune_Coefficient_PPP'\n",
    ")]\n",
    "for (xvar, yvar) in xyvars:\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.scatter(z[xvar], z[yvar], c=100*z['Sim_Result'], s=5*z['Sim_Result'], cmap='jet')\n",
    "    plt.xlabel(xvar); plt.ylabel(yvar)\n",
    "    plt.xlim([param_info.loc[xvar, 'Min'], param_info.loc[xvar, 'Max']])\n",
    "    plt.ylim([param_info.loc[yvar, 'Min'], param_info.loc[yvar, 'Max']])\n",
    "    # TODO: Show as surface and plot desired result as isocline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we get to do some History Matching!\n",
    "# Begin by creating an instance of the HistoryMatching class\n",
    "print(type(results))\n",
    "ext = 'svg' # Filetype for figures produced by history matching\n",
    "hm = HistoryMatching(\n",
    "    cut_name = cut_name,\n",
    "    param_info = param_info,\n",
    "    inputs = samples,\n",
    "    results = results.squeeze(),\n",
    "    desired_result = desired_result,\n",
    "    desired_result_var = desired_result_std**2,\n",
    "    iteration = iteration,\n",
    "    implausibility_threshold = implausibility_threshold,\n",
    "    discrepancy_var = discrepancy_std**2,\n",
    "    training_fraction = training_fraction,\n",
    "    fig_type = ext\n",
    ")\n",
    "hm.save() # Save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    existing_basis = True\n",
    "    need_basis = True\n",
    "    with open(os.path.join('Cuts', cut_name, 'basis_glm.json')) as data_file:\n",
    "        config = json.load( data_file )\n",
    "        basis_glm = Basis.deserialize(config['Basis'])\n",
    "        fitted_values = pd.read_json(config['Fitted_Values'], orient='split').set_index(['Sample_Id', 'Sim_Id']).squeeze()\n",
    "except:\n",
    "    existing_basis = False\n",
    "    \n",
    "if existing_basis:\n",
    "    print('Found existing GLM basis with the following terms:')\n",
    "    display(basis_glm.model_terms)\n",
    "    reply = input('Would you like to use this basis? [Y]/n: ')\n",
    "    \n",
    "    if reply.lower() != 'n':\n",
    "        need_basis = False\n",
    "    \n",
    "if need_basis:\n",
    "    basis_glm = Basis.polynomial_basis(params=param_names, intercept = True, first_order=True, second_order=True, third_order=False, param_info=param_info)\n",
    "\n",
    "    basis_glm.plot_regularize(samples, results, alpha = np.logspace(-5, -2, 15), scaleX=True)\n",
    "    alpha_glm = float(input('What would you like to use for the GLM regularization parameter, alpha_glm = '))\n",
    "#     alpha_glm = 1e-1\n",
    "    \n",
    "    fitted_values = basis_glm.regularize(samples, results, alpha = alpha_glm, scaleX=True)\n",
    "    print('Regularization for GLM selected:\\n', ' *','\\n * '.join(basis_glm.get_terms()))\n",
    "    with open(os.path.join('Cuts', cut_name, 'basis_glm.json'), 'w') as fout:\n",
    "        json.dump( {\n",
    "            'Basis': basis_glm.serialize(),\n",
    "            'Fitted_Values': fitted_values.reset_index().to_json(orient='split')\n",
    "        }, fout, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit the glm and plot\n",
    "\n",
    "### GLM ###############################################################\n",
    "print(\"=\"*80, \"\\nGeneralized Linear Modeling\\n\", \"=\"*80)\n",
    "#######################################################################\n",
    "f = hm.glm(\n",
    "    basis = basis_glm,\n",
    "    family = 'Poisson',\n",
    "    force_optimize_glm = True,\n",
    "    glm_fit_maxiter = 1000,\n",
    "    plot = True, #force_optimize_glm,\n",
    "    plot_data = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(fix_glob(os.path.join(hm.glmdir, \"PairwiseResults\", \"*.%s\"%ext))):\n",
    "    img = IFrame(file, width=800, height=600)\n",
    "    print(file)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Results get saved to disk, so load and display:\n",
    "for file in glob.glob(fix_glob(os.path.join(hm.glmdir, \"GLM Predicted vs Actual*.%s\"%ext))):\n",
    "    img = IFrame(file, width=800, height=600)\n",
    "    print(file)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_gpr = Basis.polynomial_basis(\n",
    "#     params =  [\n",
    "# 'Scale_Factor_Age_a', \n",
    "# 'Cumulative_Exposure_Immune_Coefficient_TM',\n",
    "# 'Recent_Exposure_Immune_Coefficient_PPP',\n",
    "# 'Recent_Exposure_Immune_Coefficient_TM',\n",
    "# 'Parasite_Density_Wave_Sigma',\n",
    "# 'Immune_Modifier_Include_Age',\n",
    "# 'Immune_Modifier_Include_Strain_Diversity',\n",
    "# 'Immune_Modifier_Include_Cumulative_Exposure'\n",
    "#               ],\n",
    "    params = param_info.index.values, \n",
    "    intercept = False, \n",
    "    first_order = True, \n",
    "    param_info=param_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### GPR ###############################################################\n",
    "print(\"=\"*80, \"\\nGaussian Process Regression\\n\", \"=\"*80)\n",
    "#######################################################################\n",
    "hm.gpr(\n",
    "    basis = basis_gpr,\n",
    "    force_optimize_gpr = True,\n",
    "\n",
    "    sigma2_f_guess = 0.6,\n",
    "    sigma2_f_bounds = (0.1, 1000),\n",
    "    sigma2_n_guess =  2.0,\n",
    "    sigma2_n_bounds = (0.01, 100),\n",
    "\n",
    "    #lengthscale_guess = [7.49636161e+01 4.30910765e-02 2.18296911e+01 8.08185597e+01\n",
    "#  5.86791240e-02 4.55925184e+01 7.61216580e+01 3.72424498e-01\n",
    "#  9.24611775e-01 7.41104089e-01]\n",
    "    lengthscale_guess = 0.25,\n",
    "    lengthscale_bounds = (0.01, 100),\n",
    "\n",
    "    optimize_sigma2_n = True,\n",
    "    log_transform = False,\n",
    "\n",
    "    verbose = True,\n",
    "    optimizer_options = {\n",
    "        'eps': 5e-3,\n",
    "        'disp': True,\n",
    "        'maxiter': 15000,\n",
    "        'ftol': 2 * np.finfo(float).eps,\n",
    "        'gtol': 2 * np.finfo(float).eps,\n",
    "    },\n",
    "    plot = True, #force_optimize_gpr,\n",
    "    plot_data = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = param_info.loc[basis_gpr.param_dict.keys()].reset_index()\n",
    "pi['Lengthscale'] = hm.gpr_model.theta[2:]\n",
    "print(pi[['Name', 'Lengthscale']].sort_values('Lengthscale'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results get saved to disk, so load and display:\n",
    "for file in glob.glob(fix_glob(os.path.join(hm.gprdir, \"PairwiseResults\", \"*.%s\"%ext))):\n",
    "    img = IFrame(file, width=800, height=600)\n",
    "    print(file)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implausibility ############################################################\n",
    "print(\"=\"*80, \"\\nImplausibility\\n\", \"=\"*80)\n",
    "###############################################################################\n",
    "hm.calc_and_plot_implausibility(\n",
    "    plot = True,\n",
    "    do_plot_data = False,\n",
    "    plot_data_highlight = pd.DataFrame() #hm.test_data.loc['prime.000049']\n",
    ") \n",
    "    #plot_data_highlight=pd.DataFrame() # plot_data_highlight=hm.training_data.loc['prime.000049']\n",
    "\n",
    "hm.training_data.to_excel(os.path.join('Cuts', cut_name, 'train_data.xlsx'))\n",
    "hm.test_data.to_excel(os.path.join('Cuts', cut_name, 'test_data.xlsx'))\n",
    "\n",
    "print('Good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results get saved to disk, so load and display:\n",
    "for file in glob.glob(fix_glob(os.path.join(hm.combineddir, \"*.%s\"%ext))):\n",
    "    img = IFrame(file, width=800, height=600)\n",
    "    print(file)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = all_results.reset_index()\n",
    "\n",
    "data = ar.loc[ar['AgeBin']==age_bin[0]].groupby(['Sample_Id','AgeBin'])['Result'].mean().reset_index().set_index('Sample_Id')\n",
    "\n",
    "train = hm.training_data\n",
    "train['Train'] = True\n",
    "test = hm.test_data\n",
    "test['Train'] = False\n",
    "train_test = pd.concat([train, test])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,10))\n",
    "\n",
    "# Reference\n",
    "#ref_by_year = reference_data[['Prevalence']].reset_index()\n",
    "\n",
    "ref_by_year = ref_df.loc[ref_df['Age bin'] == int(age_bin[0][:2])] \\\n",
    "    .groupby('Age bin') \\\n",
    "    .mean() \\\n",
    "    .reset_index()\n",
    "print(ref_by_year)\n",
    "print(data)\n",
    "sns.lineplot(data=ref_by_year, x='Age bin', y='Mean', color='k', marker='o', alpha=1, lw=2, zorder=1);\n",
    "\n",
    "# Sims\n",
    "tmp = data.merge(train_test[['Sample_Orig', 'Implausible', 'Train']], left_on='Sample_Id', right_on='Sample_Orig')\n",
    "print(tmp.head())\n",
    "sns.lineplot(data=tmp, x='AgeBin', y='Result', hue='Implausible', style='Train', \n",
    "             units='Sample_Orig', estimator=None, alpha=0.5, lw=0.5,\n",
    "             ax=ax, zorder=-1)\n",
    "ax.set_xlabel('AgeBin');\n",
    "ax.set_ylabel('Duration');\n",
    "ax.set_xticks(ref_by_year['Age bin'].unique());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
